{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict the German Election - Machine Learning Final Model AFD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[MLENS] backend: threading\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Load libraries\"\"\"\n",
    "\n",
    "# libraries for time-series utilities\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from pandas.tseries.holiday import USFederalHolidayCalendar as calendar\n",
    "\n",
    "# libraries for data transformation, visualization and modeling\n",
    "import pandas_gbq as gbq\n",
    "import pyreadr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from matplotlib.dates import DateFormatter\n",
    "import matplotlib.dates as mdates\n",
    "import os\n",
    "import sys\n",
    "\n",
    "#libraries for machine learning\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from mlens.ensemble import SuperLearner\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "#libraries for metrics\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-10-23</th>\n",
       "      <td>5.045125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-24</th>\n",
       "      <td>5.051701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-25</th>\n",
       "      <td>5.058277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-26</th>\n",
       "      <td>5.049102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-27</th>\n",
       "      <td>5.039927</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             support\n",
       "date                \n",
       "2013-10-23  5.045125\n",
       "2013-10-24  5.051701\n",
       "2013-10-25  5.058277\n",
       "2013-10-26  5.049102\n",
       "2013-10-27  5.039927"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Set-up data\"\"\"\n",
    "\n",
    "#set working directory \n",
    "path = \"/Users/dangngochuy/Desktop/Hertie/Hertie 3rd semester/Machine Learning/Predicting-German-Election/Code/Transformed Data\"\n",
    "os.chdir(path)\n",
    "\n",
    "#load data\n",
    "afd = pd.read_csv(\"combined_data_afd.csv\", index_col='date', parse_dates=True)\n",
    "afd.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering for Machine Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Create utilities for time-series modeling.\"\"\"\n",
    "\n",
    "def _keep(window, windows):\n",
    "  \"\"\"Helper function for creating rolling windows.\"\"\"\n",
    "  windows.append(window.copy())\n",
    "  return -1.  # Float return value required for Pandas apply.\n",
    "\n",
    "\n",
    "def create_rolling_features_label(series, window_size, pred_offset, pred_n=1):\n",
    "  \"\"\"Computes rolling window of the series and creates rolling window of label.\"\"\"\n",
    "  if series.isnull().sum() > 0:\n",
    "    raise ValueError('Series must not contain missing values.')\n",
    "  if pred_n < 1:\n",
    "    raise ValueError('pred_n must not be < 1.')\n",
    "  if len(series) < (window_size + pred_offset + pred_n):\n",
    "    raise ValueError('window_size + pred_offset + pred_n must not be greater '\n",
    "                     'than series length.')\n",
    "  total_steps = len(series)\n",
    "\n",
    "  def compute_rolling_window(series, window_size):\n",
    "    # Accumulate series into list.\n",
    "    windows = []\n",
    "    series.rolling(window_size)\\\n",
    "      .apply(_keep, args=(windows,))\n",
    "    return np.array(windows)\n",
    "\n",
    "  features_start = 0\n",
    "  features_end = total_steps - (pred_offset - 1) - pred_n\n",
    "  historical_windows = compute_rolling_window(\n",
    "      series[features_start:features_end], window_size)\n",
    "  # Get label pred_offset steps into the future.\n",
    "  label_start, label_end = window_size + pred_offset - 1, total_steps\n",
    "  label_series = series[label_start:label_end]\n",
    "  y = compute_rolling_window(label_series, pred_n)\n",
    "  if pred_n == 1:\n",
    "    columns = ['label']\n",
    "  else:\n",
    "    columns = ['label_{}_steps'.format(i) for i in range(pred_n)]\n",
    "  # Make dataframe. Combine features and labels.\n",
    "  label_ix = label_series.index[0:len(label_series) + 1 - pred_n]\n",
    "  df = pd.DataFrame(y, columns=columns, index=label_ix)\n",
    "  df.index.name = 'pred_date'\n",
    "  # Populate dataframe with past sales.\n",
    "  for day in range(window_size - 1, -1, -1):\n",
    "    day_rel_label = pred_offset + window_size - day - 1\n",
    "    df.insert(0, '-{}_steps'.format(day_rel_label), historical_windows[:, day])\n",
    "  return df\n",
    "\n",
    "\n",
    "def add_aggregate_features(df, time_series_col_names):\n",
    "  \"\"\"Compute summary statistic features for every row of dataframe.\"\"\"\n",
    "  x = df[time_series_col_names]\n",
    "  features = {}\n",
    "  features['mean'] = x.mean(axis=1)\n",
    "  features['std'] = x.std(axis=1)\n",
    "  features['min'] = x.min(axis=1)\n",
    "  features['max'] = x.max(axis=1)\n",
    "  percentiles = range(10, 100, 20)\n",
    "  for p in percentiles:\n",
    "    features['{}_per'.format(p)] = np.percentile(x, p, axis=1)\n",
    "  df_features = pd.DataFrame(features, index=x.index)\n",
    "  return df_features.merge(df, left_index=True, right_index=True)\n",
    "\n",
    "\n",
    "def move_column_to_end(df, column_name):\n",
    "  temp = df[column_name]\n",
    "  df.drop(column_name, axis=1, inplace=True)\n",
    "  df[column_name] = temp\n",
    "\n",
    "\n",
    "def is_between_dates(dates, start=None, end=None):\n",
    "  \"\"\"Return boolean indices indicating if dates occurs between start and end.\"\"\"\n",
    "  if start is None:\n",
    "    start = pd.to_datetime(0)\n",
    "  if end is None:\n",
    "    end = pd.to_datetime(sys.maxsize)\n",
    "  date_series = pd.Series(pd.to_datetime(dates))\n",
    "  return date_series.between(start, end).values\n",
    "\n",
    "\n",
    "def _count_holidays(dates, months, weeks):\n",
    "  \"\"\"Count number of holidays spanned in prediction windows.\"\"\"\n",
    "  cal = calendar()\n",
    "  holidays = cal.holidays(start=dates.min(), end=dates.max())\n",
    "\n",
    "  def count_holidays_during_month(date):\n",
    "    n_holidays = 0\n",
    "    beg = date\n",
    "    end = date + pd.DateOffset(months=months, weeks=weeks)\n",
    "    for h in holidays:\n",
    "      if beg <= h < end:\n",
    "        n_holidays += 1\n",
    "    return n_holidays\n",
    "\n",
    "  return pd.Series(dates).apply(count_holidays_during_month)\n",
    "\n",
    "\n",
    "def _get_day_of_month(x):\n",
    "  \"\"\"From a datetime object, extract day of month.\"\"\"\n",
    "  return int(x.strftime('%d'))\n",
    "\n",
    "\n",
    "def add_date_features(df, dates, months, weeks, inplace=False):\n",
    "  \"\"\"Create features using date that is being predicted on.\"\"\"\n",
    "  if not inplace:\n",
    "    df = df.copy()\n",
    "  df['doy'] = dates.dayofyear\n",
    "  df['dom'] = dates.map(_get_day_of_month)\n",
    "  df['month'] = dates.month\n",
    "  df['year'] = dates.year\n",
    "  df['n_holidays'] = _count_holidays(dates, months, weeks).values\n",
    "  return df\n",
    "\n",
    "\n",
    "class Metrics(object):\n",
    "  \"\"\"Performance metrics for regressor.\"\"\"\n",
    "\n",
    "  def __init__(self, y_true, predictions):\n",
    "    self.y_true = y_true\n",
    "    self.predictions = predictions\n",
    "    self.residuals = self.y_true - self.predictions\n",
    "    self.rmse = self.calculate_rmse(self.residuals)\n",
    "    self.mae = self.calculate_mae(self.residuals)\n",
    "    self.malr = self.calculate_malr(self.y_true, self.predictions)\n",
    "\n",
    "  def calculate_rmse(self, residuals):\n",
    "    \"\"\"Root mean squared error.\"\"\"\n",
    "    return np.sqrt(np.mean(np.square(residuals)))\n",
    "\n",
    "  def calculate_mae(self, residuals):\n",
    "    \"\"\"Mean absolute error.\"\"\"\n",
    "    return np.mean(np.abs(residuals))\n",
    "\n",
    "  def calculate_malr(self, y_true, predictions):\n",
    "    \"\"\"Mean absolute log ratio.\"\"\"\n",
    "    return np.mean(np.abs(np.log(1 + predictions) - np.log(1 + y_true)))\n",
    "\n",
    "  def report(self, name=None):\n",
    "    if name is not None:\n",
    "      print_string = '{} results'.format(name)\n",
    "      print(print_string)\n",
    "      print('~' * len(print_string))\n",
    "    print('RMSE: {:2.3f}\\nMAE: {:2.3f}\\nMALR: {:2.3f}'.format(\n",
    "        self.rmse, self.mae, self.malr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Create parameters for rolling window features\"\"\"\n",
    "\n",
    "WINDOW_SIZE = 30  # Timesteps to be used as features in modeling, can be a hyperparameter for tuning\n",
    "HORIZON = 3 # Predict approximately 3 days into the future\n",
    "LABELS_SIZE = 1  # The label will be the voteshare of 1 day\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dangngochuy/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:24: FutureWarning: Currently, 'apply' passes the values as ndarrays to the applied function. In the future, this will change to passing it as Series objects. You need to specify 'raw=True' to keep the current behaviour, and you can pass 'raw=False' to silence this warning\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>-32_steps</th>\n",
       "      <th>-31_steps</th>\n",
       "      <th>-30_steps</th>\n",
       "      <th>-29_steps</th>\n",
       "      <th>-28_steps</th>\n",
       "      <th>-27_steps</th>\n",
       "      <th>-26_steps</th>\n",
       "      <th>-25_steps</th>\n",
       "      <th>-24_steps</th>\n",
       "      <th>-23_steps</th>\n",
       "      <th>...</th>\n",
       "      <th>-11_steps</th>\n",
       "      <th>-10_steps</th>\n",
       "      <th>-9_steps</th>\n",
       "      <th>-8_steps</th>\n",
       "      <th>-7_steps</th>\n",
       "      <th>-6_steps</th>\n",
       "      <th>-5_steps</th>\n",
       "      <th>-4_steps</th>\n",
       "      <th>-3_steps</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pred_date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-09-17</th>\n",
       "      <td>8.102721</td>\n",
       "      <td>8.138466</td>\n",
       "      <td>8.174212</td>\n",
       "      <td>8.209957</td>\n",
       "      <td>8.286518</td>\n",
       "      <td>8.363080</td>\n",
       "      <td>8.439641</td>\n",
       "      <td>8.525727</td>\n",
       "      <td>8.591404</td>\n",
       "      <td>8.658442</td>\n",
       "      <td>...</td>\n",
       "      <td>9.126160</td>\n",
       "      <td>9.205651</td>\n",
       "      <td>9.319466</td>\n",
       "      <td>9.433281</td>\n",
       "      <td>9.567504</td>\n",
       "      <td>9.701727</td>\n",
       "      <td>9.825746</td>\n",
       "      <td>9.949765</td>\n",
       "      <td>10.073783</td>\n",
       "      <td>10.350602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-18</th>\n",
       "      <td>8.138466</td>\n",
       "      <td>8.174212</td>\n",
       "      <td>8.209957</td>\n",
       "      <td>8.286518</td>\n",
       "      <td>8.363080</td>\n",
       "      <td>8.439641</td>\n",
       "      <td>8.525727</td>\n",
       "      <td>8.591404</td>\n",
       "      <td>8.658442</td>\n",
       "      <td>8.694867</td>\n",
       "      <td>...</td>\n",
       "      <td>9.205651</td>\n",
       "      <td>9.319466</td>\n",
       "      <td>9.433281</td>\n",
       "      <td>9.567504</td>\n",
       "      <td>9.701727</td>\n",
       "      <td>9.825746</td>\n",
       "      <td>9.949765</td>\n",
       "      <td>10.073783</td>\n",
       "      <td>10.177394</td>\n",
       "      <td>10.416797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-19</th>\n",
       "      <td>8.174212</td>\n",
       "      <td>8.209957</td>\n",
       "      <td>8.286518</td>\n",
       "      <td>8.363080</td>\n",
       "      <td>8.439641</td>\n",
       "      <td>8.525727</td>\n",
       "      <td>8.591404</td>\n",
       "      <td>8.658442</td>\n",
       "      <td>8.694867</td>\n",
       "      <td>8.710884</td>\n",
       "      <td>...</td>\n",
       "      <td>9.319466</td>\n",
       "      <td>9.433281</td>\n",
       "      <td>9.567504</td>\n",
       "      <td>9.701727</td>\n",
       "      <td>9.825746</td>\n",
       "      <td>9.949765</td>\n",
       "      <td>10.073783</td>\n",
       "      <td>10.177394</td>\n",
       "      <td>10.284406</td>\n",
       "      <td>10.482993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-20</th>\n",
       "      <td>8.209957</td>\n",
       "      <td>8.286518</td>\n",
       "      <td>8.363080</td>\n",
       "      <td>8.439641</td>\n",
       "      <td>8.525727</td>\n",
       "      <td>8.591404</td>\n",
       "      <td>8.658442</td>\n",
       "      <td>8.694867</td>\n",
       "      <td>8.710884</td>\n",
       "      <td>8.726902</td>\n",
       "      <td>...</td>\n",
       "      <td>9.433281</td>\n",
       "      <td>9.567504</td>\n",
       "      <td>9.701727</td>\n",
       "      <td>9.825746</td>\n",
       "      <td>9.949765</td>\n",
       "      <td>10.073783</td>\n",
       "      <td>10.177394</td>\n",
       "      <td>10.284406</td>\n",
       "      <td>10.350602</td>\n",
       "      <td>10.527211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-21</th>\n",
       "      <td>8.286518</td>\n",
       "      <td>8.363080</td>\n",
       "      <td>8.439641</td>\n",
       "      <td>8.525727</td>\n",
       "      <td>8.591404</td>\n",
       "      <td>8.658442</td>\n",
       "      <td>8.694867</td>\n",
       "      <td>8.710884</td>\n",
       "      <td>8.726902</td>\n",
       "      <td>8.742919</td>\n",
       "      <td>...</td>\n",
       "      <td>9.567504</td>\n",
       "      <td>9.701727</td>\n",
       "      <td>9.825746</td>\n",
       "      <td>9.949765</td>\n",
       "      <td>10.073783</td>\n",
       "      <td>10.177394</td>\n",
       "      <td>10.284406</td>\n",
       "      <td>10.350602</td>\n",
       "      <td>10.416797</td>\n",
       "      <td>10.571429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            -32_steps  -31_steps  -30_steps  -29_steps  -28_steps  -27_steps  \\\n",
       "pred_date                                                                      \n",
       "2017-09-17   8.102721   8.138466   8.174212   8.209957   8.286518   8.363080   \n",
       "2017-09-18   8.138466   8.174212   8.209957   8.286518   8.363080   8.439641   \n",
       "2017-09-19   8.174212   8.209957   8.286518   8.363080   8.439641   8.525727   \n",
       "2017-09-20   8.209957   8.286518   8.363080   8.439641   8.525727   8.591404   \n",
       "2017-09-21   8.286518   8.363080   8.439641   8.525727   8.591404   8.658442   \n",
       "\n",
       "            -26_steps  -25_steps  -24_steps  -23_steps  ...  -11_steps  \\\n",
       "pred_date                                               ...              \n",
       "2017-09-17   8.439641   8.525727   8.591404   8.658442  ...   9.126160   \n",
       "2017-09-18   8.525727   8.591404   8.658442   8.694867  ...   9.205651   \n",
       "2017-09-19   8.591404   8.658442   8.694867   8.710884  ...   9.319466   \n",
       "2017-09-20   8.658442   8.694867   8.710884   8.726902  ...   9.433281   \n",
       "2017-09-21   8.694867   8.710884   8.726902   8.742919  ...   9.567504   \n",
       "\n",
       "            -10_steps  -9_steps  -8_steps   -7_steps   -6_steps   -5_steps  \\\n",
       "pred_date                                                                    \n",
       "2017-09-17   9.205651  9.319466  9.433281   9.567504   9.701727   9.825746   \n",
       "2017-09-18   9.319466  9.433281  9.567504   9.701727   9.825746   9.949765   \n",
       "2017-09-19   9.433281  9.567504  9.701727   9.825746   9.949765  10.073783   \n",
       "2017-09-20   9.567504  9.701727  9.825746   9.949765  10.073783  10.177394   \n",
       "2017-09-21   9.701727  9.825746  9.949765  10.073783  10.177394  10.284406   \n",
       "\n",
       "             -4_steps   -3_steps      label  \n",
       "pred_date                                    \n",
       "2017-09-17   9.949765  10.073783  10.350602  \n",
       "2017-09-18  10.073783  10.177394  10.416797  \n",
       "2017-09-19  10.177394  10.284406  10.482993  \n",
       "2017-09-20  10.284406  10.350602  10.527211  \n",
       "2017-09-21  10.350602  10.416797  10.571429  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Create rolling window dataframe with 30 timesteps for each parties\"\"\"\n",
    "\n",
    "afd_series = pd.Series(afd['support'], index=afd.index)\n",
    "afd_df = create_rolling_features_label(afd_series, window_size=WINDOW_SIZE, pred_offset=HORIZON)\n",
    "afd_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Create features and targets; training and test sets for AFD\"\"\"\n",
    "\n",
    "# Features, label.\n",
    "X = afd_df.drop('label', axis=1)\n",
    "y = afd_df['label']\n",
    "\n",
    "# Train/test split. Splitting on time.\n",
    "train_ix = is_between_dates(y.index,\n",
    "                                  end='2017-06-30')\n",
    "test_ix = is_between_dates(y.index,\n",
    "                                 start='2017-06-30',\n",
    "                                 end='2017-09-21')\n",
    "X_train, y_train = X.iloc[train_ix], y.iloc[train_ix]\n",
    "X_test, y_test = X.iloc[test_ix], y.iloc[test_ix]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression results\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "RMSE: 0.059\n",
      "MAE: 0.047\n",
      "MALR: 0.005\n",
      "R2 train:  0.9996008352647894\n",
      "R2 test:  0.9950034158724038\n",
      "Election day prediction with Linear Regression:  [10.6843783]\n",
      "RMSE Linear Regression: 1.916\n"
     ]
    }
   ],
   "source": [
    "# Linear Regression Model\n",
    "lin = LinearRegression()\n",
    "lin.fit(X_train, y_train)\n",
    "lin_pred = lin.predict(X_test)\n",
    "linear_regression_metrics = Metrics(y_test, lin_pred)\n",
    "linear_regression_metrics.report(\"Linear Regression\")\n",
    "\n",
    "# Look at the R^2 scores on train and test\n",
    "print(\"R2 train: \", lin.score(X_train, y_train))\n",
    "print(\"R2 test: \", lin.score(X_test, y_test))\n",
    "\n",
    "# Election day result prediction \n",
    "test_lin = y_test.tail(30).to_frame()\n",
    "test_lin_transposed = test_lin.T\n",
    "election_lin = lin.predict(test_lin_transposed)\n",
    "print(\"Election day prediction with Linear Regression: \", election_lin)\n",
    "\n",
    "#Compute RMSE of election day prediction\n",
    "actual_y = np.array([12.6])\n",
    "rmse_lin = np.sqrt(mean_squared_error(actual_y, election_lin))\n",
    "print('RMSE Linear Regression: %.3f' % rmse_lin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree results\n",
      "~~~~~~~~~~~~~~~~~~~~~\n",
      "RMSE: 0.212\n",
      "MAE: 0.171\n",
      "MALR: 0.019\n",
      "R2 train:  0.9999999998893979\n",
      "R2 test:  0.9345718984381008\n",
      "Election day prediction with Decision Tree:  [10.78694471]\n",
      "RMSE Decision Tree: 1.813\n"
     ]
    }
   ],
   "source": [
    "# Create a decision tree regression model with default arguments\n",
    "dt = DecisionTreeRegressor()\n",
    "dt.fit(X_train, y_train)\n",
    "dt_pred = dt.predict(X_test)\n",
    "decision_tree_metrics = Metrics(y_test, dt_pred)\n",
    "decision_tree_metrics.report(\"Decision Tree\")\n",
    "\n",
    "# Look at the R^2 scores on train and test\n",
    "print(\"R2 train: \", dt.score(X_train, y_train))\n",
    "print(\"R2 test: \", dt.score(X_test, y_test))\n",
    "\n",
    "# Election day result prediction \n",
    "test_dt = y_test.tail(30).to_frame()\n",
    "test_dt_transposed = test_dt.T\n",
    "election_dt = dt.predict(test_dt_transposed)\n",
    "print(\"Election day prediction with Decision Tree: \", election_dt)\n",
    "\n",
    "#Compute RMSE of election day prediction\n",
    "rmse_dt = np.sqrt(mean_squared_error(actual_y, election_dt))\n",
    "print('RMSE Decision Tree: %.3f' % rmse_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forest Model results\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "RMSE: 0.131\n",
      "MAE: 0.104\n",
      "MALR: 0.011\n",
      "R2 train:  0.999935149148537\n",
      "R2 test:  0.9752072477504128\n",
      "Election day prediction with Random Forest:  [10.78659159]\n",
      "RMSE Random Forest: 1.813\n"
     ]
    }
   ],
   "source": [
    "# Train model.\n",
    "rf = RandomForestRegressor(n_estimators=500, random_state=10, criterion='mse')\n",
    "rf.fit(X_train, y_train)\n",
    "rf_pred = rf.predict(X_test)\n",
    "random_forest_metrics = Metrics(y_test, rf_pred)\n",
    "random_forest_metrics.report(\"Forest Model\")\n",
    "\n",
    "# Look at the R^2 scores on train and test\n",
    "print(\"R2 train: \", rf.score(X_train, y_train))\n",
    "print(\"R2 test: \", rf.score(X_test, y_test))\n",
    "\n",
    "# Election day result prediction \n",
    "test_rf = y_test.tail(30).to_frame()\n",
    "test_rf_transposed = test_rf.T\n",
    "election_rf = rf.predict(test_rf_transposed)\n",
    "print(\"Election day prediction with Random Forest: \", election_rf)\n",
    "\n",
    "#Compute RMSE of election day prediction\n",
    "rmse_rf = np.sqrt(mean_squared_error(actual_y, election_rf))\n",
    "print('RMSE Random Forest: %.3f' % rmse_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get feature importances from our random forest model\n",
    "importances = rf.feature_importances_\n",
    "importances = importances[importances != 0]\n",
    "\n",
    "feature_names = list(X_test.columns.values)\n",
    "features = afd_df[feature_names]\n",
    "\n",
    "\n",
    "# Get the index of importances from greatest importance to least\n",
    "sorted_index = np.argsort(importances)[::-1]\n",
    "x = range(len(importances))\n",
    "\n",
    "# Create tick labels \n",
    "labels = np.array(feature_names)[sorted_index]\n",
    "plt.bar(x, importances[sorted_index], tick_label=labels)\n",
    "\n",
    "# Rotate tick labels to vertical\n",
    "plt.xticks(rotation=90)\n",
    "plt.title(\"Feature importances from Random Forest model\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting results\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "RMSE: 0.163\n",
      "MAE: 0.124\n",
      "MALR: 0.013\n",
      "R2 train:  0.9995217077775767\n",
      "R2 test:  0.9612879285683977\n",
      "Election day prediction with Gradient Boosting:  [10.7533973]\n",
      "RMSE Gradient Boosting: 1.847\n"
     ]
    }
   ],
   "source": [
    "# Create GB model\n",
    "gbr = GradientBoostingRegressor()\n",
    "gbr.fit(X_train, y_train)\n",
    "gbr_pred = gbr.predict(X_test)\n",
    "gradient_boosting_metrics = Metrics(y_test, gbr_pred)\n",
    "gradient_boosting_metrics.report(\"Gradient Boosting\")\n",
    "\n",
    "# Look at the R^2 scores on train and test\n",
    "print(\"R2 train: \", gbr.score(X_train, y_train))\n",
    "print(\"R2 test: \", gbr.score(X_test, y_test))\n",
    "\n",
    "# Election day result prediction \n",
    "test_gbr = y_test.tail(30).to_frame()\n",
    "test_gbr_transposed = test_gbr.T\n",
    "election_gbr = gbr.predict(test_gbr_transposed)\n",
    "print(\"Election day prediction with Gradient Boosting: \", election_gbr)\n",
    "\n",
    "#Compute RMSE of election day prediction\n",
    "rmse_gbr = np.sqrt(mean_squared_error(actual_y, election_gbr))\n",
    "print('RMSE Gradient Boosting: %.3f' % rmse_gbr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dangngochuy/anaconda3/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost results\n",
      "~~~~~~~~~~~~~~~\n",
      "RMSE: 0.163\n",
      "MAE: 0.124\n",
      "MALR: 0.013\n",
      "R2 train:  0.9994852347675696\n",
      "R2 test:  0.9595300432453533\n",
      "Election day prediction with XGBoost:  [10.720659]\n",
      "RMSE XGBoost: 1.879\n"
     ]
    }
   ],
   "source": [
    "# Create the xgboost model and fit to the training data\n",
    "xgb= XGBRegressor()\n",
    "xgb.fit(X_train, y_train)\n",
    "xgb_pred = xgb.predict(X_test)\n",
    "XGBoost_metrics = Metrics(y_test, gbr_pred)\n",
    "XGBoost_metrics.report(\"XGBoost\")\n",
    "\n",
    "# Look at the R^2 scores on train and test\n",
    "print(\"R2 train: \", xgb.score(X_train, y_train))\n",
    "print(\"R2 test: \", xgb.score(X_test, y_test))\n",
    "\n",
    "# Election day result prediction \n",
    "test_xgb = y_test.tail(30).to_frame()\n",
    "test_xgb_transposed = test_xgb.T\n",
    "\n",
    "# Get feature names: \n",
    "feature_names = list(X_test.columns.values)\n",
    "test_xgb_transposed.columns = feature_names\n",
    "election_xgb = xgb.predict(test_xgb_transposed)\n",
    "print(\"Election day prediction with XGBoost: \", election_xgb)\n",
    "\n",
    "#Compute RMSE of election day prediction\n",
    "rmse_xgb = np.sqrt(mean_squared_error(actual_y, election_xgb))\n",
    "print('RMSE XGBoost: %.3f' % rmse_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_afd = np.sqrt(mean_squared_error([12.6], [9.8]))\n",
    "rmse_spd = np.sqrt(mean_squared_error([20.5], [22.1]))\n",
    "rmse_lin = np.sqrt(mean_squared_error([9.2], [9.2]))\n",
    "rmse_gru = np.sqrt(mean_squared_error([8.9], [7.8]))\n",
    "rmse_fdp = np.sqrt(mean_squared_error([10.7], [9.2]))\n",
    "rmse_cdu = np.sqrt(mean_squared_error([32.9], [36.2]))\n",
    "rmse_oth = np.sqrt(mean_squared_error([5], [5.7]))\n",
    "\n",
    "avg_rmse = (rmse_afd + rmse_spd + rmse_lin + rmse_gru + rmse_fdp + rmse_cdu + rmse_oth) / 7\n",
    "print(\"RMSE of AFD Model: \", rmse_afd)\n",
    "print(\"RMSE of SPD Model: \", rmse_spd)\n",
    "print(\"RMSE of Die Linke Model: \", rmse_lin)\n",
    "print(\"RMSE of Green Party Model: \", rmse_gru)\n",
    "print(\"RMSE of FDP Model: \", rmse_fdp)\n",
    "print(\"RMSE of CDU Model: \", rmse_cdu)\n",
    "print(\"RMSE of Other Parties Model: \", rmse_oth)\n",
    "print(\"Average RMSE of RNN Model: \", avg_rmse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
